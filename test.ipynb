{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imdb = pd.read_csv('clean_data_imdb.csv')\n",
    "data_bechdel = pd.read_csv('clean_data_bechdel.csv')\n",
    "data_character = pd.read_csv('clean_data_character.csv')\n",
    "data_original = pd.read_csv('clean_data_original.csv')\n",
    "ethnicity_df = pd.read_csv('ethnicity_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ethnicity_ID</th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>ethnicity_label</th>\n",
       "      <th>corresponding_ethnicity</th>\n",
       "      <th>count</th>\n",
       "      <th>ethnic_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canadian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Q49085</td>\n",
       "      <td>African Americans</td>\n",
       "      <td>https://en.wikipedia.org/wiki/African_Americans</td>\n",
       "      <td>1464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/m/064b9n</td>\n",
       "      <td>Q120601</td>\n",
       "      <td>Omaha Tribe of Nebraska</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Omaha_people</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/m/041rx</td>\n",
       "      <td>Q7325</td>\n",
       "      <td>Jewish people</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jews</td>\n",
       "      <td>703</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/m/033tf_</td>\n",
       "      <td>Q1075293</td>\n",
       "      <td>Irish Americans</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Irish_Americans</td>\n",
       "      <td>196</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 ethnicity_ID wikidata_id          ethnicity_label  \\\n",
       "0           0   /m/044038p         NaN                 Canadian   \n",
       "1           1      /m/0x67      Q49085        African Americans   \n",
       "2           2    /m/064b9n     Q120601  Omaha Tribe of Nebraska   \n",
       "3           3     /m/041rx       Q7325            Jewish people   \n",
       "4           4    /m/033tf_    Q1075293          Irish Americans   \n",
       "\n",
       "                           corresponding_ethnicity  count  ethnic_cat  \n",
       "0                                              NaN    145           0  \n",
       "1  https://en.wikipedia.org/wiki/African_Americans   1464           1  \n",
       "2       https://en.wikipedia.org/wiki/Omaha_people      1           2  \n",
       "3               https://en.wikipedia.org/wiki/Jews    703           3  \n",
       "4    https://en.wikipedia.org/wiki/Irish_Americans    196           4  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_df['ethnic_cat'] = ethnicity_df.index\n",
    "data_character = pd.merge(data_character, ethnicity_df[['ethnicity_ID', 'ethnic_cat']], on='ethnicity_ID', how='left')\n",
    "\n",
    "ethnicity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imdb['num_actors'] = data_imdb['Movie_ID'].map(\n",
    "                                                    data_character.groupby('Movie_ID')['Actor_ID'].nunique()\n",
    "                                                    )\n",
    "\n",
    "data_imdb['num_women'] = data_imdb['Movie_ID'].map(\n",
    "                                                    data_character[data_character['actor_gender']=='F'].groupby('Movie_ID')['Actor_ID'].nunique()\n",
    "                                                )\n",
    "\n",
    "data_imdb['ratio_W/M'] = data_imdb['num_women']/data_imdb['num_actors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_data = data_character[data_character['actor_gender']=='F'].copy()\n",
    "men_data = data_character[data_character['actor_gender']=='M'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "boolean value of NA is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[204], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m low_count_ethnicities \u001b[38;5;241m=\u001b[39m ethnicity_df\u001b[38;5;241m.\u001b[39mloc[ethnicity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124methnic_cat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 2\u001b[0m women_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124methnic_cat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m women_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124methnic_cat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mNA \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m low_count_ethnicities \u001b[38;5;28;01melse\u001b[39;00m x)\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[204], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m low_count_ethnicities \u001b[38;5;241m=\u001b[39m ethnicity_df\u001b[38;5;241m.\u001b[39mloc[ethnicity_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124methnic_cat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 2\u001b[0m women_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124methnic_cat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m women_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124methnic_cat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mNA \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m low_count_ethnicities \u001b[38;5;28;01melse\u001b[39;00m x)\n",
      "File \u001b[0;32mmissing.pyx:392\u001b[0m, in \u001b[0;36mpandas._libs.missing.NAType.__bool__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: boolean value of NA is ambiguous"
     ]
    }
   ],
   "source": [
    "low_count_ethnicities = ethnicity_df.loc[ethnicity_df['count'] < 10, 'ethnic_cat'].tolist()\n",
    "women_data['ethnic_cat'] = women_data['ethnic_cat'].apply(lambda x: pd.NA if x in low_count_ethnicities else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mask = (data_imdb['ratio_W/M'] >= 0.5) & (data_imdb['num_actors'] > 4)\n",
    "data_imdb_women = data_imdb[valid_mask].copy()\n",
    "\n",
    "\n",
    "\n",
    "analysis = pd.merge(\n",
    "                        women_data.dropna(subset=['actor_age_movie_released'])[['actor_age_movie_released', 'Movie_ID', 'actor_name', 'ethnic_cat', 'actor_height']],\n",
    "                        data_imdb_women.dropna(subset=['SuccessMetric'])[['title', 'SuccessMetric', 'Movie_ID', 'ratio_W/M', 'Rating']],\n",
    "                        on='Movie_ID',\n",
    "                        how = 'inner'\n",
    "                        )\n",
    "\n",
    "mean_women_data = analysis.groupby('Movie_ID').agg(\n",
    "                                                    mean_age=('actor_age_movie_released', 'mean'),\n",
    "                                                    num_women=('actor_age_movie_released', 'size'),\n",
    "                                                    title=('title', 'first'),\n",
    "                                                    SuccessMetric=('SuccessMetric', 'first'),\n",
    "                                                    ratio_W_M = ('ratio_W/M', 'first'),\n",
    "                                                    ethnicities = ('ethnic_cat', lambda x: [eth for eth in x if pd.notna(eth)]),\n",
    "                                                    avg_height = ('actor_height', 'mean'),\n",
    "                                                    Rating = ('Rating', 'first')\n",
    "                                                ).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>mean_age</th>\n",
       "      <th>num_women</th>\n",
       "      <th>title</th>\n",
       "      <th>SuccessMetric</th>\n",
       "      <th>ratio_W_M</th>\n",
       "      <th>ethnicities</th>\n",
       "      <th>avg_height</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/014kkm</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>5</td>\n",
       "      <td>The Bad and the Beautiful</td>\n",
       "      <td>0.390420</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[3.0]</td>\n",
       "      <td>1.652500</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/015_1c</td>\n",
       "      <td>40.857143</td>\n",
       "      <td>7</td>\n",
       "      <td>Desk Set</td>\n",
       "      <td>0.360304</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.663750</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/015qqg</td>\n",
       "      <td>39.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>Julia</td>\n",
       "      <td>0.358721</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>[76.0, 80.0]</td>\n",
       "      <td>1.736667</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/016yxn</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>Reversal of Fortune</td>\n",
       "      <td>0.362774</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>[48.0]</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/016z5x</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>Chaplin</td>\n",
       "      <td>0.376704</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[4.0, 84.0, 19.0]</td>\n",
       "      <td>1.667143</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Movie_ID   mean_age  num_women                      title  SuccessMetric  \\\n",
       "0  /m/014kkm  28.600000          5  The Bad and the Beautiful       0.390420   \n",
       "1  /m/015_1c  40.857143          7                   Desk Set       0.360304   \n",
       "2  /m/015qqg  39.166667          6                      Julia       0.358721   \n",
       "3  /m/016yxn  41.000000          5        Reversal of Fortune       0.362774   \n",
       "4  /m/016z5x  28.666667          9                    Chaplin       0.376704   \n",
       "\n",
       "   ratio_W_M        ethnicities  avg_height  Rating  \n",
       "0   0.500000              [3.0]    1.652500     7.8  \n",
       "1   0.615385                 []    1.663750     7.2  \n",
       "2   0.545455       [76.0, 80.0]    1.736667     7.1  \n",
       "3   0.555556             [48.0]    1.660000     7.2  \n",
       "4   0.500000  [4.0, 84.0, 19.0]    1.667143     7.5  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_women_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnic_cat</th>\n",
       "      <th>mean_with_ethnic_cat</th>\n",
       "      <th>mean_without_ethnic_cat</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.31955</td>\n",
       "      <td>0.317516</td>\n",
       "      <td>0.834147</td>\n",
       "      <td>0.404322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.31955</td>\n",
       "      <td>0.321195</td>\n",
       "      <td>-0.638220</td>\n",
       "      <td>0.523433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.31955</td>\n",
       "      <td>0.320789</td>\n",
       "      <td>-0.508870</td>\n",
       "      <td>0.610916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.31955</td>\n",
       "      <td>0.318346</td>\n",
       "      <td>0.500226</td>\n",
       "      <td>0.616981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.31955</td>\n",
       "      <td>0.318787</td>\n",
       "      <td>0.317490</td>\n",
       "      <td>0.750911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.31955</td>\n",
       "      <td>0.318782</td>\n",
       "      <td>0.312944</td>\n",
       "      <td>0.754364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.31955</td>\n",
       "      <td>0.318978</td>\n",
       "      <td>0.238303</td>\n",
       "      <td>0.811675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.31955</td>\n",
       "      <td>0.319002</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>0.820558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>192.0</td>\n",
       "      <td>0.31955</td>\n",
       "      <td>0.320084</td>\n",
       "      <td>-0.225692</td>\n",
       "      <td>0.821468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>113.0</td>\n",
       "      <td>0.31955</td>\n",
       "      <td>0.319041</td>\n",
       "      <td>0.212659</td>\n",
       "      <td>0.831618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ethnic_cat  mean_with_ethnic_cat  mean_without_ethnic_cat    t_stat  \\\n",
       "7         24.0               0.31955                 0.317516  0.834147   \n",
       "0          3.0               0.31955                 0.321195 -0.638220   \n",
       "9          1.0               0.31955                 0.320789 -0.508870   \n",
       "44        25.0               0.31955                 0.318346  0.500226   \n",
       "12        43.0               0.31955                 0.318787  0.317490   \n",
       "3         48.0               0.31955                 0.318782  0.312944   \n",
       "24        75.0               0.31955                 0.318978  0.238303   \n",
       "10        22.0               0.31955                 0.319002  0.226863   \n",
       "61       192.0               0.31955                 0.320084 -0.225692   \n",
       "75       113.0               0.31955                 0.319041  0.212659   \n",
       "\n",
       "     p_value  \n",
       "7   0.404322  \n",
       "0   0.523433  \n",
       "9   0.610916  \n",
       "44  0.616981  \n",
       "12  0.750911  \n",
       "3   0.754364  \n",
       "24  0.811675  \n",
       "10  0.820558  \n",
       "61  0.821468  \n",
       "75  0.831618  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_list = []\n",
    "\n",
    "# Get the list of unique ethnic categories (excluding NaNs)\n",
    "all_ethnic_cats = pd.Series([eth for sublist in mean_women_data['ethnicities'] for eth in sublist if pd.notna(eth)]).unique()\n",
    "\n",
    "# Iterate through each ethnic category\n",
    "for ethnic_cat in all_ethnic_cats:\n",
    "    # Filter out movies that include this ethnic category\n",
    "    all_movies = mean_women_data.copy()\n",
    "    movies_without_ethnic_cat = all_movies[all_movies['ethnicities'].apply(lambda x: isinstance(x, list) and ethnic_cat not in x)]\n",
    "\n",
    "    \n",
    "    # Check if there are enough data points for comparison\n",
    "    if all_movies.empty or movies_without_ethnic_cat.empty:\n",
    "        continue\n",
    "    \n",
    "    # Calculate mean success scores\n",
    "    mean_with = all_movies['SuccessMetric'].mean()\n",
    "    mean_without = movies_without_ethnic_cat['SuccessMetric'].mean()\n",
    "    \n",
    "    # Check for zero variance\n",
    "    if all_movies['SuccessMetric'].var() == 0 or movies_without_ethnic_cat['SuccessMetric'].var() == 0:\n",
    "        t_stat, p_value = np.nan, np.nan\n",
    "    else:\n",
    "        # Perform a t-test\n",
    "        t_stat, p_value = ttest_ind(\n",
    "            all_movies['SuccessMetric'].dropna(),\n",
    "            movies_without_ethnic_cat['SuccessMetric'].dropna(),\n",
    "            equal_var=False\n",
    "        )\n",
    "    \n",
    "    # Store the results\n",
    "    results_list.append({\n",
    "        'ethnic_cat': ethnic_cat,\n",
    "        'mean_with_ethnic_cat': mean_with,\n",
    "        'mean_without_ethnic_cat': mean_without,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_value\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Sort the results by p-value\n",
    "results_df = results_df.sort_values(by='p_value')\n",
    "\n",
    "# Display the results\n",
    "results_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough movies for comparison for ethnicity: 262.0\n",
      "Not enough movies for comparison for ethnicity: 182.0\n",
      "Not enough movies for comparison for ethnicity: 285.0\n",
      "Not enough movies for comparison for ethnicity: 133.0\n",
      "Not enough movies for comparison for ethnicity: 250.0\n",
      "Not enough movies for comparison for ethnicity: 222.0\n",
      "Not enough movies for comparison for ethnicity: 160.0\n",
      "Not enough movies for comparison for ethnicity: 202.0\n",
      "Not enough movies for comparison for ethnicity: 103.0\n",
      "Not enough movies for comparison for ethnicity: 163.0\n",
      "Not enough movies for comparison for ethnicity: 320.0\n",
      "Not enough movies for comparison for ethnicity: 142.0\n",
      "Not enough movies for comparison for ethnicity: 237.0\n",
      "Not enough movies for comparison for ethnicity: 66.0\n",
      "Not enough movies for comparison for ethnicity: 156.0\n",
      "Not enough movies for comparison for ethnicity: 161.0\n",
      "Not enough movies for comparison for ethnicity: 287.0\n",
      "Not enough movies for comparison for ethnicity: 105.0\n",
      "Not enough movies for comparison for ethnicity: 112.0\n",
      "Not enough movies for comparison for ethnicity: 77.0\n",
      "Not enough movies for comparison for ethnicity: 16.0\n",
      "Not enough movies for comparison for ethnicity: 186.0\n",
      "Not enough movies for comparison for ethnicity: 124.0\n",
      "Not enough movies for comparison for ethnicity: 211.0\n",
      "Not enough movies for comparison for ethnicity: 272.0\n",
      "Not enough movies for comparison for ethnicity: 149.0\n",
      "Not enough movies for comparison for ethnicity: 197.0\n",
      "Not enough movies for comparison for ethnicity: 143.0\n",
      "Not enough movies for comparison for ethnicity: 14.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnic_cat</th>\n",
       "      <th>nb_movies_with</th>\n",
       "      <th>nb_movies_without</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>mean_with_ethnic_cat</th>\n",
       "      <th>mean_without_ethnic_cat</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>204.0</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>-0.013977</td>\n",
       "      <td>0.305605</td>\n",
       "      <td>0.319582</td>\n",
       "      <td>-8.177953</td>\n",
       "      <td>2.272104e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>113.0</td>\n",
       "      <td>14</td>\n",
       "      <td>852</td>\n",
       "      <td>0.031441</td>\n",
       "      <td>0.350482</td>\n",
       "      <td>0.319041</td>\n",
       "      <td>5.107586</td>\n",
       "      <td>1.226577e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>25.0</td>\n",
       "      <td>38</td>\n",
       "      <td>828</td>\n",
       "      <td>0.027423</td>\n",
       "      <td>0.345770</td>\n",
       "      <td>0.318346</td>\n",
       "      <td>4.112173</td>\n",
       "      <td>1.759567e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>256.0</td>\n",
       "      <td>3</td>\n",
       "      <td>863</td>\n",
       "      <td>-0.055811</td>\n",
       "      <td>0.263932</td>\n",
       "      <td>0.319743</td>\n",
       "      <td>-15.295686</td>\n",
       "      <td>4.039768e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.0</td>\n",
       "      <td>97</td>\n",
       "      <td>769</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>0.335670</td>\n",
       "      <td>0.317516</td>\n",
       "      <td>3.349117</td>\n",
       "      <td>1.083927e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ethnic_cat  nb_movies_with  nb_movies_without  mean_diff  \\\n",
       "98       204.0               2                864  -0.013977   \n",
       "67       113.0              14                852   0.031441   \n",
       "40        25.0              38                828   0.027423   \n",
       "93       256.0               3                863  -0.055811   \n",
       "7         24.0              97                769   0.018154   \n",
       "\n",
       "    mean_with_ethnic_cat  mean_without_ethnic_cat     t_stat       p_value  \n",
       "98              0.305605                 0.319582  -8.177953  2.272104e-15  \n",
       "67              0.350482                 0.319041   5.107586  1.226577e-04  \n",
       "40              0.345770                 0.318346   4.112173  1.759567e-04  \n",
       "93              0.263932                 0.319743 -15.295686  4.039768e-04  \n",
       "7               0.335670                 0.317516   3.349117  1.083927e-03  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_list = []\n",
    "\n",
    "# Get the list of unique ethnic categories (excluding NaNs)\n",
    "all_ethnic_cats = pd.Series([eth for sublist in mean_women_data['ethnicities'] for eth in sublist if pd.notna(eth)]).unique()\n",
    "\n",
    "# Iterate through each ethnic category\n",
    "for ethnic_cat in all_ethnic_cats:\n",
    "    # Filter out movies that include this ethnic category\n",
    "    movies_with_ethnic_cat = mean_women_data[mean_women_data['ethnicities'].apply(lambda x: isinstance(x, list) and ethnic_cat in x)]\n",
    "    movies_without_ethnic_cat = mean_women_data[mean_women_data['ethnicities'].apply(lambda x: isinstance(x, list) and ethnic_cat not in x)]\n",
    "\n",
    "    # Check if there are enough data points for comparison\n",
    "    if len(movies_with_ethnic_cat) < 2 or len(movies_without_ethnic_cat) < 2:\n",
    "        print(f\"Not enough movies for comparison for ethnicity: {ethnic_cat}\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate mean success scores\n",
    "    mean_with = movies_with_ethnic_cat['SuccessMetric'].mean()\n",
    "    mean_without = movies_without_ethnic_cat['SuccessMetric'].mean()\n",
    "    \n",
    "    # Check for low variance or insufficient unique values\n",
    "    if movies_with_ethnic_cat['SuccessMetric'].nunique() < 2 or movies_without_ethnic_cat['SuccessMetric'].nunique() < 2:\n",
    "        t_stat, p_value = np.nan, np.nan\n",
    "    else:\n",
    "        # Perform a t-test\n",
    "        t_stat, p_value = ttest_ind(\n",
    "            movies_with_ethnic_cat['SuccessMetric'].dropna(),\n",
    "            movies_without_ethnic_cat['SuccessMetric'].dropna(),\n",
    "            equal_var=False\n",
    "        )\n",
    "    \n",
    "    # Store the results\n",
    "    results_list.append({\n",
    "        'ethnic_cat': ethnic_cat,\n",
    "        'nb_movies_with':  len(movies_with_ethnic_cat),\n",
    "        'nb_movies_without': len(movies_without_ethnic_cat),\n",
    "        'mean_diff': mean_with - mean_without,\n",
    "        'mean_with_ethnic_cat': mean_with,\n",
    "        'mean_without_ethnic_cat': mean_without,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_value\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Sort the results by p-value\n",
    "results_df = results_df.sort_values(by='p_value')\n",
    "\n",
    "# Display the top 5 results\n",
    "results_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnic_cat</th>\n",
       "      <th>nb_movies_with</th>\n",
       "      <th>nb_movies_without</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>mean_with_ethnic_cat</th>\n",
       "      <th>mean_without_ethnic_cat</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>204.0</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>-0.013977</td>\n",
       "      <td>0.305605</td>\n",
       "      <td>0.319582</td>\n",
       "      <td>-8.177953</td>\n",
       "      <td>2.272104e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>113.0</td>\n",
       "      <td>14</td>\n",
       "      <td>852</td>\n",
       "      <td>0.031441</td>\n",
       "      <td>0.350482</td>\n",
       "      <td>0.319041</td>\n",
       "      <td>5.107586</td>\n",
       "      <td>1.226577e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>25.0</td>\n",
       "      <td>38</td>\n",
       "      <td>828</td>\n",
       "      <td>0.027423</td>\n",
       "      <td>0.345770</td>\n",
       "      <td>0.318346</td>\n",
       "      <td>4.112173</td>\n",
       "      <td>1.759567e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>256.0</td>\n",
       "      <td>3</td>\n",
       "      <td>863</td>\n",
       "      <td>-0.055811</td>\n",
       "      <td>0.263932</td>\n",
       "      <td>0.319743</td>\n",
       "      <td>-15.295686</td>\n",
       "      <td>4.039768e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.0</td>\n",
       "      <td>97</td>\n",
       "      <td>769</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>0.335670</td>\n",
       "      <td>0.317516</td>\n",
       "      <td>3.349117</td>\n",
       "      <td>1.083927e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>166.0</td>\n",
       "      <td>6</td>\n",
       "      <td>860</td>\n",
       "      <td>-0.038692</td>\n",
       "      <td>0.281126</td>\n",
       "      <td>0.319818</td>\n",
       "      <td>-3.851863</td>\n",
       "      <td>1.073519e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>75.0</td>\n",
       "      <td>26</td>\n",
       "      <td>840</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.338021</td>\n",
       "      <td>0.318978</td>\n",
       "      <td>2.400052</td>\n",
       "      <td>2.341869e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>33.0</td>\n",
       "      <td>6</td>\n",
       "      <td>860</td>\n",
       "      <td>-0.044651</td>\n",
       "      <td>0.275208</td>\n",
       "      <td>0.319859</td>\n",
       "      <td>-2.910269</td>\n",
       "      <td>3.244262e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>192.0</td>\n",
       "      <td>7</td>\n",
       "      <td>859</td>\n",
       "      <td>-0.066159</td>\n",
       "      <td>0.253925</td>\n",
       "      <td>0.320084</td>\n",
       "      <td>-2.586316</td>\n",
       "      <td>4.109732e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>193</td>\n",
       "      <td>673</td>\n",
       "      <td>-0.007382</td>\n",
       "      <td>0.313812</td>\n",
       "      <td>0.321195</td>\n",
       "      <td>-1.971342</td>\n",
       "      <td>4.947474e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>189.0</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>-0.179845</td>\n",
       "      <td>0.140120</td>\n",
       "      <td>0.319965</td>\n",
       "      <td>-11.826276</td>\n",
       "      <td>5.082662e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>90.0</td>\n",
       "      <td>4</td>\n",
       "      <td>862</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.357076</td>\n",
       "      <td>0.319376</td>\n",
       "      <td>3.065889</td>\n",
       "      <td>5.208042e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>45.0</td>\n",
       "      <td>6</td>\n",
       "      <td>860</td>\n",
       "      <td>0.036213</td>\n",
       "      <td>0.355512</td>\n",
       "      <td>0.319299</td>\n",
       "      <td>2.513943</td>\n",
       "      <td>5.226248e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>43.0</td>\n",
       "      <td>42</td>\n",
       "      <td>824</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>0.334519</td>\n",
       "      <td>0.318787</td>\n",
       "      <td>1.987313</td>\n",
       "      <td>5.297438e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>14</td>\n",
       "      <td>852</td>\n",
       "      <td>0.016353</td>\n",
       "      <td>0.335638</td>\n",
       "      <td>0.319285</td>\n",
       "      <td>2.107381</td>\n",
       "      <td>5.313357e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>135.0</td>\n",
       "      <td>3</td>\n",
       "      <td>863</td>\n",
       "      <td>-0.038885</td>\n",
       "      <td>0.280800</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>-3.878910</td>\n",
       "      <td>5.514431e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>132.0</td>\n",
       "      <td>11</td>\n",
       "      <td>855</td>\n",
       "      <td>-0.020459</td>\n",
       "      <td>0.299351</td>\n",
       "      <td>0.319810</td>\n",
       "      <td>-2.132412</td>\n",
       "      <td>5.713010e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>0.057922</td>\n",
       "      <td>0.377338</td>\n",
       "      <td>0.319416</td>\n",
       "      <td>8.261214</td>\n",
       "      <td>6.047296e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>863</td>\n",
       "      <td>0.039652</td>\n",
       "      <td>0.359064</td>\n",
       "      <td>0.319412</td>\n",
       "      <td>3.363859</td>\n",
       "      <td>7.382060e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.0</td>\n",
       "      <td>39</td>\n",
       "      <td>827</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>0.331157</td>\n",
       "      <td>0.319002</td>\n",
       "      <td>1.825387</td>\n",
       "      <td>7.478149e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>125.0</td>\n",
       "      <td>4</td>\n",
       "      <td>862</td>\n",
       "      <td>-0.040459</td>\n",
       "      <td>0.279278</td>\n",
       "      <td>0.319737</td>\n",
       "      <td>-2.642065</td>\n",
       "      <td>7.556386e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>174.0</td>\n",
       "      <td>4</td>\n",
       "      <td>862</td>\n",
       "      <td>-0.025918</td>\n",
       "      <td>0.293751</td>\n",
       "      <td>0.319669</td>\n",
       "      <td>-2.414978</td>\n",
       "      <td>9.040107e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>198.0</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>0.064425</td>\n",
       "      <td>0.383826</td>\n",
       "      <td>0.319401</td>\n",
       "      <td>6.156431</td>\n",
       "      <td>9.394764e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23.0</td>\n",
       "      <td>7</td>\n",
       "      <td>859</td>\n",
       "      <td>0.033946</td>\n",
       "      <td>0.353221</td>\n",
       "      <td>0.319275</td>\n",
       "      <td>1.975587</td>\n",
       "      <td>9.468886e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>862</td>\n",
       "      <td>-0.034927</td>\n",
       "      <td>0.284784</td>\n",
       "      <td>0.319711</td>\n",
       "      <td>-2.376272</td>\n",
       "      <td>9.568339e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>-0.028965</td>\n",
       "      <td>0.290652</td>\n",
       "      <td>0.319617</td>\n",
       "      <td>-4.912393</td>\n",
       "      <td>9.914167e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>47.0</td>\n",
       "      <td>10</td>\n",
       "      <td>856</td>\n",
       "      <td>0.029391</td>\n",
       "      <td>0.348602</td>\n",
       "      <td>0.319210</td>\n",
       "      <td>1.824983</td>\n",
       "      <td>1.005744e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>216.0</td>\n",
       "      <td>9</td>\n",
       "      <td>857</td>\n",
       "      <td>0.027077</td>\n",
       "      <td>0.346345</td>\n",
       "      <td>0.319268</td>\n",
       "      <td>1.819170</td>\n",
       "      <td>1.054327e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>41.0</td>\n",
       "      <td>4</td>\n",
       "      <td>862</td>\n",
       "      <td>0.014574</td>\n",
       "      <td>0.334056</td>\n",
       "      <td>0.319482</td>\n",
       "      <td>2.127358</td>\n",
       "      <td>1.126313e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>227.0</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.241610</td>\n",
       "      <td>0.319730</td>\n",
       "      <td>-5.262856</td>\n",
       "      <td>1.149975e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ethnic_cat  nb_movies_with  nb_movies_without  mean_diff  \\\n",
       "98        204.0               2                864  -0.013977   \n",
       "67        113.0              14                852   0.031441   \n",
       "40         25.0              38                828   0.027423   \n",
       "93        256.0               3                863  -0.055811   \n",
       "7          24.0              97                769   0.018154   \n",
       "33        166.0               6                860  -0.038692   \n",
       "23         75.0              26                840   0.019043   \n",
       "84         33.0               6                860  -0.044651   \n",
       "56        192.0               7                859  -0.066159   \n",
       "0           3.0             193                673  -0.007382   \n",
       "57        189.0               2                864  -0.179845   \n",
       "65         90.0               4                862   0.037700   \n",
       "70         45.0               6                860   0.036213   \n",
       "12         43.0              42                824   0.015733   \n",
       "1          76.0              14                852   0.016353   \n",
       "81        135.0               3                863  -0.038885   \n",
       "46        132.0              11                855  -0.020459   \n",
       "89         65.0               2                864   0.057922   \n",
       "54        100.0               3                863   0.039652   \n",
       "10         22.0              39                827   0.012155   \n",
       "99        125.0               4                862  -0.040459   \n",
       "75        174.0               4                862  -0.025918   \n",
       "24        198.0               2                864   0.064425   \n",
       "20         23.0               7                859   0.033946   \n",
       "43         44.0               4                862  -0.034927   \n",
       "115        67.0               2                864  -0.028965   \n",
       "18         47.0              10                856   0.029391   \n",
       "19        216.0               9                857   0.027077   \n",
       "86         41.0               4                862   0.014574   \n",
       "113       227.0               2                864  -0.078120   \n",
       "\n",
       "     mean_with_ethnic_cat  mean_without_ethnic_cat     t_stat       p_value  \n",
       "98               0.305605                 0.319582  -8.177953  2.272104e-15  \n",
       "67               0.350482                 0.319041   5.107586  1.226577e-04  \n",
       "40               0.345770                 0.318346   4.112173  1.759567e-04  \n",
       "93               0.263932                 0.319743 -15.295686  4.039768e-04  \n",
       "7                0.335670                 0.317516   3.349117  1.083927e-03  \n",
       "33               0.281126                 0.319818  -3.851863  1.073519e-02  \n",
       "23               0.338021                 0.318978   2.400052  2.341869e-02  \n",
       "84               0.275208                 0.319859  -2.910269  3.244262e-02  \n",
       "56               0.253925                 0.320084  -2.586316  4.109732e-02  \n",
       "0                0.313812                 0.321195  -1.971342  4.947474e-02  \n",
       "57               0.140120                 0.319965 -11.826276  5.082662e-02  \n",
       "65               0.357076                 0.319376   3.065889  5.208042e-02  \n",
       "70               0.355512                 0.319299   2.513943  5.226248e-02  \n",
       "12               0.334519                 0.318787   1.987313  5.297438e-02  \n",
       "1                0.335638                 0.319285   2.107381  5.313357e-02  \n",
       "81               0.280800                 0.319684  -3.878910  5.514431e-02  \n",
       "46               0.299351                 0.319810  -2.132412  5.713010e-02  \n",
       "89               0.377338                 0.319416   8.261214  6.047296e-02  \n",
       "54               0.359064                 0.319412   3.363859  7.382060e-02  \n",
       "10               0.331157                 0.319002   1.825387  7.478149e-02  \n",
       "99               0.279278                 0.319737  -2.642065  7.556386e-02  \n",
       "75               0.293751                 0.319669  -2.414978  9.040107e-02  \n",
       "24               0.383826                 0.319401   6.156431  9.394764e-02  \n",
       "20               0.353221                 0.319275   1.975587  9.468886e-02  \n",
       "43               0.284784                 0.319711  -2.376272  9.568339e-02  \n",
       "115              0.290652                 0.319617  -4.912393  9.914167e-02  \n",
       "18               0.348602                 0.319210   1.824983  1.005744e-01  \n",
       "19               0.346345                 0.319268   1.819170  1.054327e-01  \n",
       "86               0.334056                 0.319482   2.127358  1.126313e-01  \n",
       "113              0.241610                 0.319730  -5.262856  1.149975e-01  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
